package org.rolson.emr.emrcycle1;

import java.util.ArrayList;
import java.util.List;
import java.util.Optional;

import com.amazonaws.auth.DefaultAWSCredentialsProviderChain;
import com.amazonaws.services.elasticmapreduce.AmazonElasticMapReduce;
import com.amazonaws.services.elasticmapreduce.AmazonElasticMapReduceClient;
import com.amazonaws.services.elasticmapreduce.AmazonElasticMapReduceClientBuilder;
import com.amazonaws.services.elasticmapreduce.model.ClusterSummary;
import com.amazonaws.services.elasticmapreduce.model.DescribeClusterRequest;
import com.amazonaws.services.elasticmapreduce.model.DescribeClusterResult;
import com.amazonaws.services.elasticmapreduce.model.ListClustersResult;

import javafx.collections.FXCollections;
import javafx.collections.ObservableList;

public class WorkflowCoordinator {
	
	private List<Cluster> clusters;
	public ObservableList<Cluster> data = FXCollections.observableArrayList();
	private AmazonElasticMapReduceClient emr;
	public WorkflowCoordinator()
	{
		//
		this.clusters = new ArrayList<Cluster>();
		//getWorkflowsFromAWS();
		//dummyWorkflows();
	}
	public void setEMRClient()
	{
		try{
			//need to update the method here
			emr = new AmazonElasticMapReduceClient(new DefaultAWSCredentialsProviderChain());
		}
		catch(Exception e){
			emr=null;
		}
		 
	}
//	public void removeWorkflow()
//	{
//		data.remove(0);
//	}
//	public void addWorkflow()
//	{
//		Workflow wf = new Workflow("workflow new");
//		data.add(wf );
//	}
//	public void updateWorkflow()
//	{
//		for(Workflow wf: workflows)
//		{
//			wf.status = "running";
//		}
//		//update cheat
//		
//		data.setAll(workflows);
//	}
//	private void dummyWorkflows()
//	{
//		for(int i=0;i<6;i++)
//		{
//			Workflow wf = new Workflow("workflow"+i);
//			wf.status = "starting";
//			wf.appType = "Spark";
//			workflows.add(wf );
//		}
//		data.setAll(workflows);
//	}
	public AmazonElasticMapReduce getClient()
	{
		return emr;
	}
	public void getWorkflowFromAWS(String clusterID)
	{
//		DescribeClusterResult clusterinfo = emr.describeCluster(new DescribeClusterRequest().withClusterId(clusterID));
//		Workflow wf = new Workflow(clusterinfo.getCluster().getName());
//		addWorkflow(wf);
	}
	public void runWorkflow(String name)
	{
		setEMRClient();
		//get the workflow by name
		Cluster clus = getCluster(name);
		if(clus!=null)
		{
			System.out.println("Starting workflow "+name);
			clus.setRequest();
			clus.setResult(emr.runJobFlow(clus.getRequest()));
			clus.setStatus("starting");
		}
		
	}
	public Cluster getCluster(String name)
	{
		Optional<Cluster> matches = clusters.stream()
				.filter(t -> t.getName() ==name)
				.findAny(); 
		if(matches.isPresent())
		{
			Cluster clus = matches.get();
			return clus;
		}
		else
		{
			return null;
		}
	}
	
	private void workflowUpdate()
	{
		//called to trigger update on monitor
		data.setAll(clusters);
	}
	public List<Workflow> getWorkflows()
	{
		return workflows;
	}
}
