package climateClusters;

import java.util.Arrays;
import java.util.List;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.mllib.linalg.Vector;
import org.joda.time.DateTime;

public class Clustering {

	public static void main(String[] args) {
		SparkConf conf = new SparkConf().setMaster("local").setAppName("App");
		JavaSparkContext jsc = new JavaSparkContext(conf);
	    List<String> reqVars  = Arrays.asList("t", "ws", "rh");
	    DateTime startdate = new DateTime(2005, 1, 1, 1, 0, 0, 0);
		DateTime enddate = new DateTime(2008, 1, 1, 1,0,0,0);
		int startSeason =0;
		int endSeason=11;
	    String path = args[0];
	    JavaRDD<String> data = jsc.textFile(path);
	    
	    JavaRDD<Vector> parsedData = data               // convert list to stream
                .filter(line -> !isHeader(line)) //filter out header with function
                .filter(line-> inDateRange(line,startdate,enddate))
                .filter(line-> inSeasonRange(line,startSeason,endSeason))
                .map(s->getValues(s,reqVars));
	}

}
